{"name":"bzip2","body":"\n\n<h1 align=\"center\">bzip2</h1>\n\n\n\n\n\n\n\n\n\n\n\n<hr>\n\n\n<h2>NAME\n<a name=\"NAME\"></a>\n</h2>\n\n\n<p style=\"margin-left:11%; margin-top: 1em\">bzip2, bunzip2\n- a block-sorting file compressor, v1.0.8 <br>\nbzcat - decompresses files to stdout <br>\nbzip2recover - recovers data from damaged bzip2 files</p>\n\n<h2>SYNOPSIS\n<a name=\"SYNOPSIS\"></a>\n</h2>\n\n\n<p style=\"margin-left:11%; margin-top: 1em\"><b>bzip2</b> [\n<b>-cdfkqstvzVL123456789</b> ] [ <i>filenames ...</i> ]\n<b><br>\nbzip2</b> [ <b>-h|--help</b> ] <b><br>\nbunzip2</b> [ <b>-fkvsVL</b> ] [ <i>filenames ...</i> ]\n<b><br>\nbunzip2</b> [ <b>-h|--help</b> ] <b><br>\nbzcat</b> [ <b>-s</b> ] [ <i>filenames ...</i> ] <b><br>\nbzcat</b> [ <b>-h|--help</b> ] <b><br>\nbzip2recover</b> <i>filename</i></p>\n\n<h2>DESCRIPTION\n<a name=\"DESCRIPTION\"></a>\n</h2>\n\n\n<p style=\"margin-left:11%; margin-top: 1em\"><i>bzip2</i>\ncompresses files using the Burrows-Wheeler block sorting\ntext compression algorithm, and Huffman coding. Compression\nis generally considerably better than that achieved by more\nconventional LZ77/LZ78-based compressors, and approaches the\nperformance of the PPM family of statistical\ncompressors.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">The\ncommand-line options are deliberately very similar to those\nof <i>GNU gzip,</i> but they are not identical.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\"><i>bzip2</i>\nexpects a list of file names to accompany the command-line\nflags. Each file is replaced by a compressed version of\nitself, with the name &quot;original_name.bz2&quot;. Each\ncompressed file has the same modification date, permissions,\nand, when possible, ownership as the corresponding original,\nso that these properties can be correctly restored at\ndecompression time. File name handling is naive in the sense\nthat there is no mechanism for preserving original file\nnames, permissions, ownerships or dates in filesystems which\nlack these concepts, or have serious file name length\nrestrictions, such as MS-DOS.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\"><i>bzip2</i>\nand <i>bunzip2</i> will by default not overwrite existing\nfiles. If you want this to happen, specify the -f flag.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">If no file\nnames are specified, <i>bzip2</i> compresses from standard\ninput to standard output. In this case, <i>bzip2</i> will\ndecline to write compressed output to a terminal, as this\nwould be entirely incomprehensible and therefore\npointless.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\"><i>bunzip2</i>\n(or <i>bzip2 -d)</i> decompresses all specified files. Files\nwhich were not created by <i>bzip2</i> will be detected and\nignored, and a warning issued. <i>bzip2</i> attempts to\nguess the filename for the decompressed file from that of\nthe compressed file as follows:</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">filename.bz2\nbecomes filename <br>\nfilename.bz becomes filename <br>\nfilename.tbz2 becomes filename.tar <br>\nfilename.tbz becomes filename.tar <br>\nanyothername becomes anyothername.out</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">If the file\ndoes not end in one of the recognised endings, <i>.bz2, .bz,\n.tbz2</i> or <i>.tbz, bzip2</i> complains that it cannot\nguess the name of the original file, and uses the original\nname with <i>.out</i> appended.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">As with\ncompression, supplying no filenames causes decompression\nfrom standard input to standard output.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\"><i>bunzip2</i>\nwill correctly decompress a file which is the concatenation\nof two or more compressed files. The result is the\nconcatenation of the corresponding uncompressed files.\nIntegrity testing (-t) of concatenated compressed files is\nalso supported.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">You can also\ncompress or decompress files to the standard output by\ngiving the -c flag. Multiple files may be compressed and\ndecompressed like this. The resulting outputs are fed\nsequentially to stdout. Compression of multiple files in\nthis manner generates a stream containing multiple\ncompressed file representations. Such a stream can be\ndecompressed correctly only by <i>bzip2</i> version 0.9.0 or\nlater. Earlier versions of <i>bzip2</i> will stop after\ndecompressing the first file in the stream.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\"><i>bzcat</i>\n(or <i>bzip2 -dc)</i> decompresses all specified files to\nthe standard output.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\"><i>bzip2</i>\nwill read arguments from the environment variables\n<i>BZIP2</i> and <i>BZIP,</i> in that order, and will\nprocess them before any arguments read from the command\nline. This gives a convenient way to supply default\narguments.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">Compression is\nalways performed, even if the compressed file is slightly\nlarger than the original. Files of less than about one\nhundred bytes tend to get larger, since the compression\nmechanism has a constant overhead in the region of 50 bytes.\nRandom data (including the output of most file compressors)\nis coded at about 8.05 bits per byte, giving an expansion of\naround 0.5%.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">As a self-check\nfor your protection, <i>bzip2</i> uses 32-bit CRCs to make\nsure that the decompressed version of a file is identical to\nthe original. This guards against corruption of the\ncompressed data, and against undetected bugs in <i>bzip2</i>\n(hopefully very unlikely). The chances of data corruption\ngoing undetected is microscopic, about one chance in four\nbillion for each file processed. Be aware, though, that the\ncheck occurs upon decompression, so it can only tell you\nthat something is wrong. It can&rsquo;t help you recover the\noriginal uncompressed data. You can use <i>bzip2recover</i>\nto try to recover data from damaged files.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">Return values:\n0 for a normal exit, 1 for environmental problems (file not\nfound, invalid flags, I/O errors, &amp;c), 2 to indicate a\ncorrupt compressed file, 3 for an internal consistency error\n(eg, bug) which caused <i>bzip2</i> to panic.</p>\n\n<h2>OPTIONS\n<a name=\"OPTIONS\"></a>\n</h2>\n\n\n<p style=\"margin-left:11%; margin-top: 1em\"><b>-c\n--stdout</b></p>\n\n<p style=\"margin-left:22%;\">Compress or decompress to\nstandard output.</p>\n\n<p style=\"margin-left:11%;\"><b>-d --decompress</b></p>\n\n<p style=\"margin-left:22%;\">Force decompression. <i>bzip2,\nbunzip2</i> and <i>bzcat</i> are really the same program,\nand the decision about what actions to take is done on the\nbasis of which name is used. This flag overrides that\nmechanism, and forces <i>bzip2</i> to decompress.</p>\n\n<p style=\"margin-left:11%;\"><b>-z --compress</b></p>\n\n<p style=\"margin-left:22%;\">The complement to -d: forces\ncompression, regardless of the invocation name.</p>\n\n<p style=\"margin-left:11%;\"><b>-t --test</b></p>\n\n<p style=\"margin-left:22%;\">Check integrity of the\nspecified file(s), but don&rsquo;t decompress them. This\nreally performs a trial decompression and throws away the\nresult.</p>\n\n<p style=\"margin-left:11%;\"><b>-f --force</b></p>\n\n<p style=\"margin-left:22%;\">Force overwrite of output\nfiles. Normally, <i>bzip2</i> will not overwrite existing\noutput files. Also forces <i>bzip2</i> to break hard links\nto files, which it otherwise wouldn&rsquo;t do.</p>\n\n<p style=\"margin-left:22%; margin-top: 1em\">bzip2 normally\ndeclines to decompress files which don&rsquo;t have the\ncorrect magic header bytes. If forced (-f), however, it will\npass such files through unmodified. This is how GNU gzip\nbehaves.</p>\n\n<p style=\"margin-left:11%;\"><b>-k --keep</b></p>\n\n<p style=\"margin-left:22%;\">Keep (don&rsquo;t delete) input\nfiles during compression or decompression.</p>\n\n<p style=\"margin-left:11%;\"><b>-s --small</b></p>\n\n<p style=\"margin-left:22%;\">Reduce memory usage, for\ncompression, decompression and testing. Files are\ndecompressed and tested using a modified algorithm which\nonly requires 2.5 bytes per block byte. This means any file\ncan be decompressed in 2300&nbsp;k of memory, albeit at\nabout half the normal speed.</p>\n\n<p style=\"margin-left:22%; margin-top: 1em\">During\ncompression, -s selects a block size of 200&nbsp;k, which\nlimits memory use to around the same figure, at the expense\nof your compression ratio. In short, if your machine is low\non memory (8 megabytes or less), use -s for everything. See\nMEMORY MANAGEMENT below.</p>\n\n<p style=\"margin-left:11%;\"><b>-q --quiet</b></p>\n\n<p style=\"margin-left:22%;\">Suppress non-essential warning\nmessages. Messages pertaining to I/O errors and other\ncritical events will not be suppressed.</p>\n\n<p style=\"margin-left:11%;\"><b>-v --verbose</b></p>\n\n<p style=\"margin-left:22%;\">Verbose mode -- show the\ncompression ratio for each file processed. Further\n-v&rsquo;s increase the verbosity level, spewing out lots of\ninformation which is primarily of interest for diagnostic\npurposes.</p>\n\n<p style=\"margin-left:11%;\"><b>-h --help</b></p>\n\n<p style=\"margin-left:22%;\">Print a help message and\nexit.</p>\n\n<p style=\"margin-left:11%;\"><b>-L --license -V\n--version</b></p>\n\n<p style=\"margin-left:22%;\">Display the software version,\nlicense terms and conditions.</p>\n\n<p style=\"margin-left:11%;\"><b>-1 (or --fast) to -9 (or\n--best)</b></p>\n\n<p style=\"margin-left:22%;\">Set the block size to 100 k,\n200 k ... 900 k when compressing. Has no effect when\ndecompressing. See MEMORY MANAGEMENT below. The --fast and\n--best aliases are primarily for GNU gzip compatibility. In\nparticular, --fast doesn&rsquo;t make things significantly\nfaster. And --best merely selects the default behaviour.</p>\n\n<table width=\"100%\" border=\"0\" rules=\"none\" frame=\"void\"\n       cellspacing=\"0\" cellpadding=\"0\">\n<tr valign=\"top\" align=\"left\">\n<td width=\"11%\"></td>\n<td width=\"3%\">\n\n\n<p><b>--</b></p></td>\n<td width=\"8%\"></td>\n<td width=\"78%\">\n\n\n<p>Treats all subsequent arguments as file names, even if\nthey start with a dash. This is so you can handle files with\nnames beginning with a dash, for example: bzip2 --\n-myfilename.</p> </td></tr>\n</table>\n\n<p style=\"margin-left:11%;\"><b>--repetitive-fast\n--repetitive-best</b></p>\n\n<p style=\"margin-left:22%;\">These flags are redundant in\nversions 0.9.5 and above. They provided some coarse control\nover the behaviour of the sorting algorithm in earlier\nversions, which was sometimes useful. 0.9.5 and above have\nan improved algorithm which renders these flags\nirrelevant.</p>\n\n<h2>MEMORY MANAGEMENT\n<a name=\"MEMORY MANAGEMENT\"></a>\n</h2>\n\n\n<p style=\"margin-left:11%; margin-top: 1em\"><i>bzip2</i>\ncompresses large files in blocks. The block size affects\nboth the compression ratio achieved, and the amount of\nmemory needed for compression and decompression. The flags\n-1 through -9 specify the block size to be 100,000 bytes\nthrough 900,000 bytes (the default) respectively. At\ndecompression time, the block size used for compression is\nread from the header of the compressed file, and\n<i>bunzip2</i> then allocates itself just enough memory to\ndecompress the file. Since block sizes are stored in\ncompressed files, it follows that the flags -1 to -9 are\nirrelevant to and so ignored during decompression.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">Compression and\ndecompression requirements, in bytes, can be estimated\nas:</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">Compression:\n400&nbsp;k + ( 8 x block size )</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">Decompression:\n100&nbsp;k + ( 4 x block size ), or <br>\n100&nbsp;k + ( 2.5 x block size )</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">Larger block\nsizes give rapidly diminishing marginal returns. Most of the\ncompression comes from the first two or three hundred k of\nblock size, a fact worth bearing in mind when using\n<i>bzip2</i> on small machines. It is also important to\nappreciate that the decompression memory requirement is set\nat compression time by the choice of block size.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">For files\ncompressed with the default 900&nbsp;k block size,\n<i>bunzip2</i> will require about 3700 kbytes to decompress.\nTo support decompression of any file on a 4 megabyte\nmachine, <i>bunzip2</i> has an option to decompress using\napproximately half this amount of memory, about 2300 kbytes.\nDecompression speed is also halved, so you should use this\noption only where necessary. The relevant flag is -s.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">In general, try\nand use the largest block size memory constraints allow,\nsince that maximises the compression achieved. Compression\nand decompression speed are virtually unaffected by block\nsize.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">Another\nsignificant point applies to files which fit in a single\nblock -- that means most files you&rsquo;d encounter using a\nlarge block size. The amount of real memory touched is\nproportional to the size of the file, since the file is\nsmaller than a block. For example, compressing a file 20,000\nbytes long with the flag -9 will cause the compressor to\nallocate around 7600&nbsp;k of memory, but only touch\n400&nbsp;k + 20000 * 8 = 560 kbytes of it. Similarly, the\ndecompressor will allocate 3700&nbsp;k but only touch\n100&nbsp;k + 20000 * 4 = 180 kbytes.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">Here is a table\nwhich summarises the maximum memory usage for different\nblock sizes. Also recorded is the total compressed size for\n14 files of the Calgary Text Compression Corpus totalling\n3,141,622 bytes. This column gives some feel for how\ncompression varies with block size. These figures tend to\nunderstate the advantage of larger block sizes for larger\nfiles, since the Corpus is dominated by smaller files.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">Compress\nDecompress Decompress Corpus <br>\nFlag usage usage -s usage Size</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">-1 1200k 500k\n350k 914704 <br>\n-2 2000k 900k 600k 877703 <br>\n-3 2800k 1300k 850k 860338 <br>\n-4 3600k 1700k 1100k 846899 <br>\n-5 4400k 2100k 1350k 845160 <br>\n-6 5200k 2500k 1600k 838626 <br>\n-7 6100k 2900k 1850k 834096 <br>\n-8 6800k 3300k 2100k 828642 <br>\n-9 7600k 3700k 2350k 828642</p>\n\n<h2>RECOVERING DATA FROM DAMAGED FILES\n<a name=\"RECOVERING DATA FROM DAMAGED FILES\"></a>\n</h2>\n\n\n<p style=\"margin-left:11%; margin-top: 1em\"><i>bzip2</i>\ncompresses files in blocks, usually 900&nbsp;kbytes long.\nEach block is handled independently. If a media or\ntransmission error causes a multi-block .bz2 file to become\ndamaged, it may be possible to recover data from the\nundamaged blocks in the file.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">The compressed\nrepresentation of each block is delimited by a 48-bit\npattern, which makes it possible to find the block\nboundaries with reasonable certainty. Each block also\ncarries its own 32-bit CRC, so damaged blocks can be\ndistinguished from undamaged ones.</p>\n\n\n<p style=\"margin-left:11%; margin-top: 1em\"><i>bzip2recover</i>\nis a simple program whose purpose is to search for blocks in\n.bz2 files, and write each block out into its own .bz2 file.\nYou can then use <i>bzip2</i> -t to test the integrity of\nthe resulting files, and decompress those which are\nundamaged.</p>\n\n\n<p style=\"margin-left:11%; margin-top: 1em\"><i>bzip2recover</i>\ntakes a single argument, the name of the damaged file, and\nwrites a number of files &quot;rec00001file.bz2&quot;,\n&quot;rec00002file.bz2&quot;, etc., containing the extracted\nblocks. The output filenames are designed so that the use of\nwildcards in subsequent processing -- for example,\n&quot;bzip2 -dc rec*file.bz2 &gt; recovered_data&quot; --\nprocesses the files in the correct order.</p>\n\n\n<p style=\"margin-left:11%; margin-top: 1em\"><i>bzip2recover</i>\nshould be of most use dealing with large .bz2 files, as\nthese will contain many blocks. It is clearly futile to use\nit on damaged single-block files, since a damaged block\ncannot be recovered. If you wish to minimise any potential\ndata loss through media or transmission errors, you might\nconsider compressing with a smaller block size.</p>\n\n<h2>PERFORMANCE NOTES\n<a name=\"PERFORMANCE NOTES\"></a>\n</h2>\n\n\n<p style=\"margin-left:11%; margin-top: 1em\">The sorting\nphase of compression gathers together similar strings in the\nfile. Because of this, files containing very long runs of\nrepeated symbols, like &quot;aabaabaabaab ...&quot;\n(repeated several hundred times) may compress more slowly\nthan normal. Versions 0.9.5 and above fare much better than\nprevious versions in this respect. The ratio between\nworst-case and average-case compression time is in the\nregion of 10:1. For previous versions, this figure was more\nlike 100:1. You can use the -vvvv option to monitor progress\nin great detail, if you want.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">Decompression\nspeed is unaffected by these phenomena.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\"><i>bzip2</i>\nusually allocates several megabytes of memory to operate in,\nand then charges all over it in a fairly random fashion.\nThis means that performance, both for compressing and\ndecompressing, is largely determined by the speed at which\nyour machine can service cache misses. Because of this,\nsmall changes to the code to reduce the miss rate have been\nobserved to give disproportionately large performance\nimprovements. I imagine <i>bzip2</i> will perform best on\nmachines with very large caches.</p>\n\n<h2>CAVEATS\n<a name=\"CAVEATS\"></a>\n</h2>\n\n\n<p style=\"margin-left:11%; margin-top: 1em\">I/O error\nmessages are not as helpful as they could be. <i>bzip2</i>\ntries hard to detect I/O errors and exit cleanly, but the\ndetails of what the problem is sometimes seem rather\nmisleading.</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">This manual\npage pertains to version 1.0.8 of <i>bzip2.</i> Compressed\ndata created by this version is entirely forwards and\nbackwards compatible with the previous public releases,\nversions 0.1pl2, 0.9.0, 0.9.5, 1.0.0, 1.0.1, 1.0.2 and\nabove, but with the following exception: 0.9.0 and above can\ncorrectly decompress multiple concatenated compressed files.\n0.1pl2 cannot do this; it will stop after decompressing just\nthe first file in the stream.</p>\n\n\n<p style=\"margin-left:11%; margin-top: 1em\"><i>bzip2recover</i>\nversions prior to 1.0.2 used 32-bit integers to represent\nbit positions in compressed files, so they could not handle\ncompressed files more than 512 megabytes long. Versions\n1.0.2 and above use 64-bit ints on some platforms which\nsupport them (GNU supported targets, and Windows). To\nestablish whether or not bzip2recover was built with such a\nlimitation, run it without arguments. In any event you can\nbuild yourself an unlimited version if you can recompile it\nwith MaybeUInt64 set to be an unsigned 64-bit integer.</p>\n\n<h2>AUTHOR\n<a name=\"AUTHOR\"></a>\n</h2>\n\n\n<p style=\"margin-left:11%; margin-top: 1em\">Julian Seward,\njseward@acm.org.</p>\n\n\n<p style=\"margin-left:11%; margin-top: 1em\">https://sourceware.org/bzip2/</p>\n\n<p style=\"margin-left:11%; margin-top: 1em\">The ideas\nembodied in <i>bzip2</i> are due to (at least) the following\npeople: Michael Burrows and David Wheeler (for the block\nsorting transformation), David Wheeler (again, for the\nHuffman coder), Peter Fenwick (for the structured coding\nmodel in the original <i>bzip,</i> and many refinements),\nand Alistair Moffat, Radford Neal and Ian Witten (for the\narithmetic coder in the original <i>bzip).</i> I am much\nindebted for their help, support and advice. See the manual\nin the source distribution for pointers to sources of\ndocumentation. Christian von Roques encouraged me to look\nfor faster sorting algorithms, so as to speed up\ncompression. Bela Lubkin encouraged me to improve the\nworst-case compression performance. Donna Robinson XMLised\nthe documentation. The bz* scripts are derived from those of\nGNU gzip. Many people sent patches, helped with portability\nproblems, lent machines, gave advice and were generally\nhelpful.</p>\n<hr>\n","headings":["<a href=\"#NAME\">NAME</a>","<a href=\"#SYNOPSIS\">SYNOPSIS</a>","<a href=\"#DESCRIPTION\">DESCRIPTION</a>","<a href=\"#OPTIONS\">OPTIONS</a>","<a href=\"#MEMORY MANAGEMENT\">MEMORY MANAGEMENT</a>","<a href=\"#RECOVERING DATA FROM DAMAGED FILES\">RECOVERING DATA FROM DAMAGED FILES</a>","<a href=\"#PERFORMANCE NOTES\">PERFORMANCE NOTES</a>","<a href=\"#CAVEATS\">CAVEATS</a>","<a href=\"#AUTHOR\">AUTHOR</a>"]}